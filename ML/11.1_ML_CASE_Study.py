# -*- coding: utf-8 -*-
"""11.1.ML_Case_Study.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hfjYVDTPzS_UdnMhsV9i6csUKZxket9V
"""

#Q1: Create a DataFrame with the following e-commerce sales data:
#Columns: OrderID, CustomerID, Product, Category, Quantity, Price, OrderDate, Rating, Review
#Create at least 50 sample records with realistic data including dates from 2023-2024
#Display the first 10 and last 5 records using head() and tail()

import pandas as pd
import numpy as np

data = [
    [1001, 5421, 'Smartphone', 'Electronics', 1, 699.99, '2023-01-15', 5, 'Excellent product!'],
    [1002, 5102, 'T-Shirt', 'Clothing', 3, 19.50, '2023-02-10', 4, 'Good value for money'],
    [1003, 5330, 'Vase', 'Home Decor', 1, 45.00, '2023-02-22', 3, 'Average quality'],
    [1004, 5215, 'Fiction Novel', 'Books', 2, 15.99, '2023-03-05', 5, 'Highly recommended'],
    [1005, 5489, 'Moisturizer', 'Beauty', 1, 25.00, '2023-03-18', 2, 'Did not meet expectations'],
    [1006, 5055, 'Laptop', 'Electronics', 1, 1200.00, '2023-04-12', 5, 'Excellent product!'],
    [1007, 5123, 'Jeans', 'Clothing', 1, 49.99, '2023-05-01', 4, 'Good value for money'],
    [1008, 5390, 'Wall Art', 'Home Decor', 2, 85.00, '2023-05-20', 5, 'Highly recommended'],
    [1009, 5201, 'Tech Manual', 'Books', 1, 55.00, '2023-06-14', 3, 'Average quality'],
    [1010, 5444, 'Perfume', 'Beauty', 1, 95.00, '2023-07-02', 4, 'Good value for money'],
    [1011, 5311, 'Headphones', 'Electronics', 1, 150.00, '2023-07-25', 5, 'Excellent product!'],
    [1012, 5098, 'Jacket', 'Clothing', 1, 120.00, '2023-08-11', 3, 'Average quality'],
    [1013, 5222, 'Cushion', 'Home Decor', 4, 20.00, '2023-09-05', 4, 'Good value for money'],
    [1014, 5477, 'Cookbook', 'Books', 1, 30.00, '2023-09-29', 5, 'Highly recommended'],
    [1015, 5150, 'Lipstick', 'Beauty', 2, 22.00, '2023-10-15', 2, 'Did not meet expectations'],
    [1016, 5305, 'Smartwatch', 'Electronics', 1, 250.00, '2023-11-03', 4, 'Good value for money'],
    [1017, 5044, 'Sneakers', 'Clothing', 1, 75.00, '2023-11-20', 5, 'Excellent product!'],
    [1018, 5288, 'Lamp', 'Home Decor', 1, 60.00, '2023-12-12', 3, 'Average quality'],
    [1019, 5410, 'Biography', 'Books', 1, 18.00, '2023-12-28', 5, 'Highly recommended'],
    [1020, 5190, 'Shampoo', 'Beauty', 2, 15.00, '2024-01-05', 4, 'Good value for money'],
    [1021, 5366, 'Tablet', 'Electronics', 1, 450.00, '2024-01-20', 5, 'Excellent product!'],
    [1022, 5077, 'Hoodie', 'Clothing', 1, 40.00, '2024-02-14', 4, 'Good value for money'],
    [1023, 5255, 'Mirror', 'Home Decor', 1, 110.00, '2024-03-01', 3, 'Average quality'],
    [1024, 5433, 'History', 'Books', 1, 22.50, '2024-03-15', 5, 'Highly recommended'],
    [1025, 5111, 'Sunscreen', 'Beauty', 3, 18.00, '2024-04-02', 4, 'Good value for money'],
    [1026, 5322, 'Smartphone', 'Electronics', 1, 699.99, '2024-04-18', 2, 'Did not meet expectations'],
    [1027, 5033, 'T-Shirt', 'Clothing', 5, 15.00, '2024-05-05', 5, 'Excellent product!'],
    [1028, 5266, 'Vase', 'Home Decor', 1, 45.00, '2024-05-22', 4, 'Good value for money'],
    [1029, 5455, 'Fiction Novel', 'Books', 1, 15.99, '2024-06-10', 3, 'Average quality'],
    [1030, 5133, 'Moisturizer', 'Beauty', 1, 25.00, '2024-06-25', 5, 'Highly recommended'],
    [1031, 5388, 'Laptop', 'Electronics', 1, 1200.00, '2024-07-12', 4, 'Good value for money'],
    [1032, 5011, 'Jeans', 'Clothing', 2, 49.99, '2024-07-28', 5, 'Excellent product!'],
    [1033, 5244, 'Wall Art', 'Home Decor', 1, 85.00, '2024-08-14', 3, 'Average quality'],
    [1034, 5488, 'Tech Manual', 'Books', 1, 55.00, '2024-08-30', 4, 'Good value for money'],
    [1035, 5166, 'Perfume', 'Beauty', 1, 95.00, '2024-09-15', 5, 'Highly recommended'],
    [1036, 5355, 'Headphones', 'Electronics', 2, 150.00, '2024-10-01', 2, 'Did not meet expectations'],
    [1037, 5001, 'Jacket', 'Clothing', 1, 120.00, '2024-10-18', 5, 'Excellent product!'],
    [1038, 5277, 'Cushion', 'Home Decor', 3, 20.00, '2024-11-05', 4, 'Good value for money'],
    [1039, 5466, 'Cookbook', 'Books', 1, 30.00, '2024-11-22', 3, 'Average quality'],
    [1040, 5144, 'Lipstick', 'Beauty', 1, 22.00, '2024-12-05', 5, 'Highly recommended'],
    [1041, 5377, 'Smartwatch', 'Electronics', 1, 250.00, '2024-12-15', 4, 'Good value for money'],
    [1042, 5022, 'Sneakers', 'Clothing', 1, 75.00, '2024-12-24', 5, 'Excellent product!'],
    [1043, 5299, 'Lamp', 'Home Decor', 2, 60.00, '2024-01-10', 3, 'Average quality'],
    [1044, 5499, 'Biography', 'Books', 1, 18.00, '2024-02-28', 4, 'Good value for money'],
    [1045, 5177, 'Shampoo', 'Beauty', 1, 15.00, '2024-03-12', 5, 'Highly recommended'],
    [1046, 5344, 'Tablet', 'Electronics', 1, 450.00, '2024-04-25', 2, 'Did not meet expectations'],
    [1047, 5088, 'Hoodie', 'Clothing', 2, 40.00, '2024-05-18', 5, 'Excellent product!'],
    [1048, 5233, 'Mirror', 'Home Decor', 1, 110.00, '2024-06-05', 4, 'Good value for money'],
    [1049, 5422, 'History', 'Books', 3, 22.50, '2024-07-20', 3, 'Average quality'],
    [1050, 5188, 'Sunscreen', 'Beauty', 1, 18.00, '2024-08-15', 5, 'Highly recommended']
]

columns = ['OrderID', 'CustomerID', 'Product', 'Category', 'Quantity', 'Price', 'OrderDate', 'Rating', 'Review']
df = pd.DataFrame(data,columns=columns)
print("first 10 records")
print(df.head(10))
print("last 5 records")
print(df.tail(5))

#Q2: Use info() and describe() to get a comprehensive overview of the dataset
#Identify data types, missing values, and statistical summary
#Print the column names using columns attribute and shape of the dataset
print(df.info())
print(df.describe())
print(df.columns)
print(df.shape)

# Q3: Introduce 10% missing values randomly in Rating and Review columns
# Detect missing values and display the count of missing values per column
# Fill missing ratings with the median rating and missing reviews with "No review provided"
import random

# Q4: Create a new column 'TotalAmount' by multiplying Quantity and Price
# Add another column 'DiscountedPrice' that applies 10% discount on orders above $100
# Use conditional selection to filter orders where TotalAmount > $150
df["TotalAmount"]=df["Quantity"]*df["Price"]
df["DiscountedPrice"]=df["TotalAmount"].where(df["TotalAmount"]>100,df["TotalAmount"]*0.9)
df_filt=df[df["TotalAmount"]>150]
df_filt

# Q5: Select only the columns: Product, Category, TotalAmount, and Rating
# Filter and display all orders from the 'Electronics' category with Rating >= 4
print(df[["Product",'Category','TotalAmount','Rating']])
print(df[(df["Category"]=="Electronics") & (df["Rating"]>=4)])

# Q6: Use boolean indexing to find all orders where:
# - Quantity > 2 AND Price < 50 OR Rating == 5
# Display the count of such orders
filt1=df[(df["Quantity"]>2) & (df["Price"]<50) | (df["Rating"]==5)]
print(filt1)
print("count of these order:",len(filt1))

# Q7: Sort the entire DataFrame by OrderDate (descending) and then by TotalAmount (descending)
# Create a new column 'SalesRank' that ranks products by TotalAmount in descending order
df.sort_values(by=["OrderDate","TotalAmount"],ascending=[False,False])
df["SalesRank"]=df["TotalAmount"].rank(ascending=False)
print(df[["OrderDate","TotalAmount","SalesRank"]])

# Q8: Find the top 5 best-selling products based on total quantity sold
# Display the product name and total quantity in descending order
top_5=df.groupby("Product")["Quantity"].sum().sort_values(ascending=False)
print(top_5.head())

# Q9: Group the data by 'Category' and calculate:
# - Total sales (sum of TotalAmount)
# - Average rating
# - Number of orders
# Display the results sorted by total sales
group_cat=df.groupby("Category")["TotalAmount"].sum()
print("Total sales (sum of TotalAmount) ",group_cat)
group_rating=df.groupby("Category")["Rating"].mean()
print("Average rating ",group_rating)
group_order=df.groupby("Category")["OrderID"].count()
print("Number of orders ",group_order)
sorted_total_sales=group_cat.sort_values(ascending=False)
print("sorted by total sales ",sorted_total_sales)

# Q10: Create a pivot table showing average Price for each Category and Rating combination
# Use groupby with multiple columns (Category, Product) and aggregate multiple functions

# Q11: Convert the Quantity and Price columns to NumPy arrays
# Create a 2D array combining these two columns
# Display array properties: shape, dtype, ndim, size
quant=df["Quantity"].to_numpy()
price=df["Price"].to_numpy()
twod_array=np.array([quant,price])
print(twod_array)
print(twod_array.shape)
print(twod_array.dtype)
print(twod_array.ndim)

# Q12: Create a 1D NumPy array of 100 random prices between 10 and 500
# Calculate mean, median, standard deviation, min, and max using NumPy functions
# Reshape this array into a 10x10 matrix
num_array=np.random.randint(10,500,100)
print(num_array)
print(np.mean(num_array))
print(np.median(num_array))
print(np.std(num_array))
print(np.min(num_array))
print(np.max(num_array))
num_array=num_array.reshape(10,10)
print(num_array)

# Q13: Create two 3D NumPy arrays (3x3x3) with random integers
# Perform element-wise addition, multiplication, and matrix multiplication
# Use boolean indexing to filter values greater than 50
arr1=np.random.randint(1,10,(3,3,3))
arr2=np.random.randint(1,10,(3,3,3))
addition=arr1+arr2
multiplication=arr1*arr2
matrix_mul=np.matmul(arr1,arr2)
print(arr1)
print(arr2)
print(addition)
print(multiplication)
print(matrix_mul)

# Q14: Create NumPy arrays using special values:
# - Array of zeros (5x5)
# - Array of ones (3x4)
# - Identity matrix (4x4)
# - Array with values from 0 to 50 with step of 5 using arange
# Concatenate and stack these arrays
z_array=np.zeros((5,5))
o_array=np.ones((3,4))
i_array=np.eye(4)
a_array=np.arange(0,51,5)
print(z_array)
print(o_array)
print(i_array)
print(a_array)

# Q15: Use array slicing to extract:
# - First 3 rows from the Quantity-Price 2D array
# - Every alternate element from the Price array
# - Diagonal elements from a 5x5 matrix of TotalAmount values
print(twod_array[:3])
print(price[::2])
print(np.diag(df["TotalAmount"]))

Q16: Create a correlation matrix between Quantity, Price, Rating, and TotalAmount using NumPy

Calculate the covariance matrix

Perform linear algebra operations: determinant and inverse of correlation matrix

Q17: Generate 1000 random samples from a normal distribution (mean=100, std=15)

Calculate percentiles: 25th, 50th, 75th, 90th, 95th

Demonstrate the difference between copy and view using these arrays

Q18: Create a random array of 1000 sales values

Use NumPy to flatten, reshape into (100, 10), and then transpose

Compare memory usage between original, copy, and view

Q19: Create a line plot showing total sales trend over months

Customize with: title, xlabel, ylabel, grid, legend

Use different line styles, colors, and markers

Q20: Create a bar chart comparing total sales across different categories

Customize colors for each bar and add value labels on top of bars

Create a horizontal bar chart as well

Q21: Create a scatter plot showing relationship between Price and Rating

Color points by Category and vary point size by Quantity

Add a trend line and customize markers

Q22: Create a histogram showing the distribution of TotalAmount

Use 20 bins and customize colors and transparency

Add a vertical line showing the mean value

Q23: Create a pie chart showing percentage distribution of sales by Category

Explode the largest segment and display percentages

Customize colors and add a legend

Q24: Create a 2x2 subplot figure containing:

- Top-left: Sales trend line plot

- Top-right: Category-wise bar chart

- Bottom-left: Rating distribution histogram

- Bottom-right: Sales by category pie chart

Save this dashboard as 'sales_dashboard.png' with 300 dpi

Q25: Create a comprehensive mini-dashboard (3x2 subplots) that includes:

- Sales over time, Category comparison, Price vs Rating scatter

- Quantity distribution, Top 5 products bar chart, Monthly growth line

Customize each subplot with titles, labels, and legends

Q26: Create a second DataFrame with customer information:

Columns: CustomerID, CustomerName, City, SignupDate

Merge this with the sales DataFrame using CustomerID (inner, left, right, outer joins)

Demonstrate the difference between merge and join operations

Q27: Create three separate DataFrames for three different months of sales data

Concatenate them vertically (along rows) and horizontally (along columns)

Remove duplicate records if any and reset the index

Q28: Convert OrderDate column to datetime format

Extract: Year, Month, Day, DayOfWeek, Quarter from OrderDate

Create a time series analysis showing sales trends by month and quarter

Calculate rolling 7-day average of sales

Q29: Using the Review column, perform comprehensive text analysis:

- Tokenize all reviews into words

- Remove stopwords from reviews

- Apply stemming and lemmatization

- Perform POS tagging on sample reviews

- Create frequency distribution of top 20 most common words

- Visualize word frequency using a bar chart

Q30: Convert Quantity, Price, and Rating columns to TensorFlow tensors

Create TensorFlow variables for Price and update them with 15% price increase

Perform tensor operations:

- Calculate predicted revenue using matrix multiplication

- Apply mathematical functions (square, sqrt, exponential) on tensors

- Demonstrate in-place operations and variable updates

Display tensor properties: shape, dtype, rank